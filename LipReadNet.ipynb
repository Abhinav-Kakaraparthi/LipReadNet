{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39c90c-7447-4735-8cd5-888ce198eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c45f3-17ff-4a97-90cc-18568903e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0e729-224f-49b9-b287-19e846040483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba460a-325c-476e-af83-d4d033bbb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bb2cc-faa7-4f79-a7fe-8832bf7170f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "output = 'data.zip'\n",
    "gdown.download(url,output, quiet = False)\n",
    "gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ccb2f-ac7d-4789-b580-a91a144163c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36cf38-99e4-452d-9015-44dc4329800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3476a65-a115-494d-a66f-1ad3855bb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22a0cd-29fe-4e2f-900c-003b3f91a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670eb47-73f8-4d22-bf86-dd1a631aed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num(['n','i','c','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf3f1b-6f94-486d-b7a1-5eae83bbae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_char([14,  9,  3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cae65-dfc3-4636-a812-4bf98e8d0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464e066-f9c6-4a8a-a441-0dabbfcac9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str): \n",
    "    path = bytes.decode(path.numpy())\n",
    "    #file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path) \n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1e133b-db37-4128-befb-115406b6375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '.\\\\data\\\\s1\\\\bbal6n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba55758-5d2c-425a-aea6-7e113a22cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2536c-2027-471c-b73d-66f1a4671e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d03649-0b25-49a1-9ce2-fb4a927cfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686d54a-9a07-45cc-ac00-c10d2a33deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1105601-7ac5-44ee-bc58-2d3deab66e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcb945-47f6-461d-8b90-5836a876202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e3dc4-9ac0-46be-ad9e-384edbb24e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split \n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b842e7f-4eac-4020-939a-678c299760ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b2bf88-3603-4217-abce-115df30da7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c088092-12c5-4bdb-b308-273c6c646658",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1084c41-4a7d-44d0-8be2-9299ad7617f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ffc54-b035-4ce6-aef1-b42698b79276",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = sample.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f6296-f4d0-4602-b911-cffc670d61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('./animation.gif', val[0][0], fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2bc3d-d637-4b60-8d27-bd8f9b58e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = (val[0][0].astype(np.uint8) * 255).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23271ca2-bb1f-4551-b91f-f720223e3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('./animation.gif', fv, duration=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a4e1a-cc13-4379-9bf3-56cc72b0ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0: videos, 0: first video out of batch, 0: return first frame of video\n",
    "plt.imshow(val[0][0][36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0dcd8-f5dd-46d1-ac83-6ad30c1127ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cb5c0-85ec-405e-a680-702a4401229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f30ea1-b858-459b-9992-ca483659cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256,3, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75,3, padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Reshape((-1,))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer = \"orthogonal\", return_sequences = True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer = \"orthogonal\", return_sequences = True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer = 'he_normal', activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b5ded-d094-43e2-8d49-929d39194fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416f6bc-5df3-4cd3-990a-87d5c82fb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ad15d-b24f-4471-952b-53f04ce954e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d285e-a5bf-4eaf-9793-2d69dce3d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35859544-690c-441c-bbac-2f0f57288eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eeff79-e8e7-4d4e-8245-b91b2d139179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a26f21-fea7-4cb4-a73c-bdbacd4e0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40921a9-39f7-45f9-b37c-fee14bf2e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss =CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ce575-51bf-413e-9c03-15962c5ddb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models', 'checkpoint.weights.h5'), monitor='loss', save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c8b99-0ccc-4f7d-94eb-4a193cba296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c9545-1206-45c6-b533-b7373fc9e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_callback = ProduceExample(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56537a06-0d88-48cc-b812-4a3ead1c966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3309bbf-38f9-499d-8136-d311aae02daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "output = 'checkpoints.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da46f4c-0fb9-475e-9969-8b2d77de14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e1dac-74a6-4299-a276-d177b65e9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2138e-11b7-4f95-886b-94ea2b4a746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e0512-5f7d-4343-a418-163b4e97b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660a022-7703-4127-8c81-f517618779b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcca6a-0736-49b4-8caf-082f1972ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a2bea-99e4-40a0-afda-b8e392f46842",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef6780-a4ba-4432-9196-035aa3e00538",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bras9a.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6497a93-1718-4d57-89f9-f0056b323d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a682516-7cbc-4550-9e58-de81384ae3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62e413-24a1-473e-ad6d-1b807c0e10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebafa756-4d5d-4710-9a6d-cd045a1aa5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39deb62-a3ac-48b4-9479-68a920c3ac01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
